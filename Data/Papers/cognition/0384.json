{"authors": [["Uddin", "Sophia", "S", "Department of Psychology, The University of Chicago, 5848 S. University Ave., Chicago, IL 60637, USA. Electronic address: sophiauddin@uchicago.edu."], ["Heald", "Shannon L M", "SLM", "Department of Psychology, The University of Chicago, 5848 S. University Ave., Chicago, IL 60637, USA."], ["Van Hedger", "Stephen C", "SC", "Department of Psychology, The University of Chicago, 5848 S. University Ave., Chicago, IL 60637, USA."], ["Klos", "Serena", "S", "Department of Psychology, The University of Chicago, 5848 S. University Ave., Chicago, IL 60637, USA."], ["Nusbaum", "Howard C", "HC", "Department of Psychology, The University of Chicago, 5848 S. University Ave., Chicago, IL 60637, USA."]], "date": "2017-12-19", "id": "29272740", "text": "There is debate about how individuals use context to successfully predict and recognize words. One view argues that context supports neural predictions that make use of the speech motor system, whereas other views argue for a sensory or conceptual level of prediction. While environmental sounds can convey clear referential meaning, they are not linguistic signals, and are thus neither produced with the vocal tract nor typically encountered in sentence context. We compared the effect of spoken sentence context on recognition and comprehension of spoken words versus nonspeech, environmental sounds. In Experiment 1, sentence context decreased the amount of signal needed for recognition of spoken words and environmental sounds in similar fashion. In Experiment 2, listeners judged sentence meaning in both high and low contextually constraining sentence frames, when the final word was present or replaced with a matching environmental sound. Results showed that sentence constraint affected decision time similarly for speech and nonspeech, such that high constraint sentences (i.e., frame plus completion) were processed faster than low constraint sentences for speech and nonspeech. Linguistic context facilitates the recognition and understanding of nonspeech sounds in much the same way as for spoken words. This argues against a simple form of a speech-motor explanation of predictive coding in spoken language understanding, and suggests support for conceptual-level predictions.", "doi": "10.1016/j.cognition.2017.12.009", "title": "Understanding environmental sounds in sentence context.", "journal": ["Cognition", "Cognition"]}