{"authors": [["Davis", "Colin J", "CJ", "University of Bristol, Bristol, United Kingdom."], ["Lupker", "Stephen J", "SJ", "University of Western Ontario, London, Ontario, Canada."]], "date": "2017-12-15", "id": "29244824", "text": "The experiments reported here used \"Reversed-Interior\" (RI) primes (e.g., cetupmor-COMPUTER) in three different masked priming paradigms in order to test between different models of orthographic coding/visual word recognition. The results of Experiment 1, using a standard masked priming methodology, showed no evidence of priming from RI primes, in contrast to the predictions of the Bayesian Reader and LTRS models. By contrast, Experiment 2, using a sandwich priming methodology, showed significant priming from RI primes, in contrast to the predictions of open bigram models, which predict that there should be no orthographic similarity between these primes and their targets. Similar results were obtained in Experiment 3, using a masked prime same-different task. The results of all three experiments are most consistent with the predictions derived from simulations of the Spatial-coding model.", "doi": "10.1371/journal.pone.0189056", "title": "A backwards glance at words: Using reversed-interior masked primes to test models of visual word identification.", "journal": ["PloS one", "PLoS ONE"]}