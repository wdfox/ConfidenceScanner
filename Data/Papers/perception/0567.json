{"authors": [["Ingram", "James N", "JN", "Department of Engineering, University of Cambridge, Trumpington Street, Cambridge, United Kingdom."], ["Sadeghi", "Mohsen", "M", "Department of Engineering, University of Cambridge, Trumpington Street, Cambridge, United Kingdom."], ["Flanagan", "J Randall", "JR", "Department of Psychology and Centre for Neuroscience Studies, Queen's University, Kingston, ON, Canada."], ["Wolpert", "Daniel M", "DM", "Department of Engineering, University of Cambridge, Trumpington Street, Cambridge, United Kingdom."]], "date": "2017-12-18", "id": "29253869", "text": "Current models of sensorimotor control posit that motor commands are generated by combining multiple modules which may consist of internal models, motor primitives or motor synergies. The mechanisms which select modules based on task requirements and modify their output during learning are therefore critical to our understanding of sensorimotor control. Here we develop a novel modular architecture for multi-dimensional tasks in which a set of fixed primitives are each able to compensate for errors in a single direction in the task space. The contribution of the primitives to the motor output is determined by both top-down contextual information and bottom-up error information. We implement this model for a task in which subjects learn to manipulate a dynamic object whose orientation can vary. In the model, visual information regarding the context (the orientation of the object) allows the appropriate primitives to be engaged. This top-down module selection is implemented by a Gaussian function tuned for the visual orientation of the object. Second, each module's contribution adapts across trials in proportion to its ability to decrease the current kinematic error. Specifically, adaptation is implemented by cosine tuning of primitives to the current direction of the error, which we show to be theoretically optimal for reducing error. This error-tuned model makes two novel predictions. First, interference should occur between alternating dynamics only when the kinematic errors associated with each oppose one another. In contrast, dynamics which lead to orthogonal errors should not interfere. Second, kinematic errors alone should be sufficient to engage the appropriate modules, even in the absence of contextual information normally provided by vision. We confirm both these predictions experimentally and show that the model can also account for data from previous experiments. Our results suggest that two interacting processes account for module selection during sensorimotor control and learning.", "doi": "10.1371/journal.pcbi.1005883", "title": "An error-tuned model for sensorimotor learning.", "journal": ["PLoS computational biology", "PLoS Comput. Biol."]}